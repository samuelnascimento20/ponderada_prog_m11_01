{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3abc8ee4",
   "metadata": {},
   "source": [
    "# Classificação de Renda com Dataset Adult (UCI)\n",
    "Este notebook demonstra a classificação binária de renda (acima ou abaixo de 50K/ano) usando o dataset Adult do UCI Machine Learning Repository e um modelo sequencial simples em Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Carregar os dados (assumindo que os arquivos CSV estão no mesmo diretório ou caminho especificado)\n",
    "# Para rodar no Google Colab, você pode precisar fazer upload dos arquivos originais (adult.data e adult.test) ou dos arquivos processados (adult_processed_train.csv e adult_processed_test.csv).\n",
    "# Se for usar os arquivos processados, descomente as linhas abaixo e comente as linhas de pré-processamento:\n",
    "# df_train = pd.read_csv('adult_processed_train.csv')\n",
    "# df_test = pd.read_csv('adult_processed_test.csv')\n",
    "\n",
    "column_names = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'\n",
    "]\n",
    "\n",
    "# Ler os arquivos inferindo o cabeçalho e especificando a codificação correta\n",
    "df_train = pd.read_csv('adult_processed_train.csv', encoding='latin-1')\n",
    "df_test = pd.read_excel('adult_processed_test.xlsx')\n",
    "# Remover linhas com valores ausentes\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "# Pré-processamento da variável target\n",
    "df_train['income'] = df_train['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "df_test['income'] = df_test['income'].apply(lambda x: 1 if x == '>50K.' else 0)\n",
    "\n",
    "# Separar features (X) e target (y)\n",
    "X_train = df_train.drop('income', axis=1)\n",
    "y_train = df_train['income']\n",
    "X_test = df_test.drop('income', axis=1)\n",
    "y_test = df_test['income']\n",
    "\n",
    "# Identificar colunas categóricas e numéricas\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X_train.select_dtypes(include=np.number).columns\n",
    "\n",
    "# One-Hot Encoding para colunas categóricas\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Alinhar colunas após One-Hot Encoding\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "X_test = X_test.loc[:, X_train.columns]\n",
    "\n",
    "# Escalonamento das features numéricas\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "print(f'Shape de X_train: {X_train.shape}')\n",
    "print(f'Shape de X_test: {X_test.shape}')\n",
    "print(f'Shape de y_train: {y_train.shape}')\n",
    "print(f'Shape de y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e804ec",
   "metadata": {},
   "source": [
    "## Exploração do Dataset\n",
    "O dataset Adult contém 48842 instâncias e 14 features, com a tarefa de prever se a renda de um indivíduo excede 50K/ano. Após a remoção de valores ausentes e o pré-processamento (One-Hot Encoding e escalonamento), o número de features pode aumentar devido às variáveis categóricas.\n",
    "\n",
    "**Características Principais:**\n",
    "*   **Número de Amostras (após limpeza):** Aproximadamente 45.222 (32.561 treino, 16.281 teste no original, mas após remoção de NaNs e alinhamento, os números podem variar ligeiramente).\n",
    "*   **Número de Features:** 14 features originais (numéricas e categóricas), expandidas após One-Hot Encoding.\n",
    "*   **Tarefa de Classificação:** Binária (renda >50K ou <=50K).\n",
    "*   **Features:** Idade, classe de trabalho, peso final (fnlwgt), educação, número de educação, estado civil, ocupação, relacionamento, raça, sexo, ganho de capital, perda de capital, horas por semana, país de origem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce62212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir o modelo Keras\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(1, activation='sigmoid', input_shape=(X_train.shape[1],))\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "# Otimizador Adam: Um algoritmo de otimização adaptativo que ajusta as taxas de aprendizado para cada parâmetro individualmente.\n",
    "# Função de Perda binary_crossentropy: Usada para problemas de classificação binária, mede a diferença entre a distribuição de probabilidade prevista e a verdadeira.\n",
    "# Métrica accuracy: Proporção de previsões corretas.\n",
    "# Métrica F1: Média harmônica da precisão e recall, útil para datasets desbalanceados.\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.F1Score(average='weighted')]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514e165e",
   "metadata": {},
   "source": [
    "## Treinamento do Modelo\n",
    "O modelo será treinado por 50 épocas com um batch size de 10. Uma parte do conjunto de treino será usada para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef67952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=10,\n",
    "    verbose=1,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e796f820",
   "metadata": {},
   "source": [
    "## Avaliação e Interpretação dos Resultados\n",
    "Após o treinamento, o modelo será avaliado no conjunto de teste para calcular a acurácia e o F1-Score. Esses resultados nos darão uma indicação do desempenho do modelo na tarefa de classificação de renda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba88c14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Prever no conjunto de teste\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_pred_proba = \u001b[43mmodel\u001b[49m.predict(X_test)\n\u001b[32m      3\u001b[39m y_pred = (y_pred_proba > \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Calcular acurácia e F1-Score\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Prever no conjunto de teste\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calcular acurácia e F1-Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Acurácia no conjunto de teste: {accuracy:.4f}')\n",
    "print(f'F1-Score no conjunto de teste: {f1:.4f}')\n",
    "\n",
    "# Interpretação dos resultados\n",
    "print('Interpretação:')\n",
    "print('A acurácia indica a proporção de previsões corretas. O F1-Score é particularmente útil em datasets desbalanceados, pois considera tanto a precisão quanto o recall.')\n",
    "print('Um modelo com uma única camada Dense pode ter um desempenho limitado para um dataset complexo como o Adult. Possíveis melhorias incluem:')\n",
    "print('- Adicionar mais camadas ocultas.')\n",
    "print('- Aumentar o número de neurônios nas camadas.')\n",
    "print('- Experimentar diferentes funções de ativação.')\n",
    "print('- Ajustar hiperparâmetros como taxa de aprendizado, batch size e número de épocas.')\n",
    "print('- Realizar engenharia de features mais avançada.')\n",
    "print('- Utilizar técnicas de regularização para evitar overfitting.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
